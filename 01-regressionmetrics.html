<!DOCTYPE html>
<html lang="en">
  

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">
  <meta http-equiv="Content-Security-Policy" content="default-src 'self'; font-src 'self' data: fonts.gstatic.com;">


  <title>Regression</title>
  <meta name="description" content="Regression Related Evaluation Metrics Regression problems are the problems where we try to make a prediction on a continuous scale. This chapter aims to help...">

  <link rel="canonical" href="http://localhost:4000/ml_handbook/01-RegressionMetrics.html">
  <link rel="alternate" type="application/rss+xml" title="Unboxing Machine Learning" href="http://localhost:4000/ml_handbook/feed.xml">

  <meta property="og:url"         content="http://localhost:4000/ml_handbook/01-RegressionMetrics.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Regression" />
<meta property="og:description" content="Regression Related Evaluation Metrics Regression problems are the problems where we try to make a prediction on a continuous scale. This chapter aims to help..." />
<meta property="og:image"       content="http://localhost:4000/ml_handbook/images/logo/logo.png" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "http://localhost:4000/ml_handbook/01-RegressionMetrics.html",
  "headline": "Regression",
  "datePublished": "2019-10-15T02:44:59-07:00",
  "dateModified": "2019-10-15T02:44:59-07:00",
  "description": "Regression Related Evaluation Metrics Regression problems are the problems where we try to make a prediction on a continuous scale. This chapter aims to help...",
  "author": {
    "@type": "Person",
    "name": "Ritesh Agrawal"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:4000/ml_handbook",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "http://localhost:4000/ml_handbook",
    "height": 60,
    "width": 60
  }
}

  </script>

  <link rel="stylesheet" href="/ml_handbook/assets/css/styles.css">
  <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/ml_handbook/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    }
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/ml_handbook';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" integrity="sha256-m1eTvwEHwmsw4+XKF7BshClVJEPwTVycveNl0CS0Mkk=" crossorigin="anonymous"></script>

  <script>
const initAnchors = () => {
  if (window.anchors === undefined) {
    setTimeout(initAnchors, 250)
    return
  }
  anchors.add("main h1, main h2, main h3, main h4")
}

initFunction(initAnchors);
</script>


  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" integrity="sha256-iM4Yzi/zLj/IshPWMC1IluRxTtRjMqjPGd97TZ9yYpU=" crossorigin="anonymous"></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Selectors for elements on the page -->
  <script>
/**
 * Select various elements on the page for later use
 */

// IDs we'll attach to cells
const codeCellId = index => `codecell${index}`
const inputCellId = index => `inputcell${index}`

pageElements = {}

// All code cells
findCodeCells = function() {
    var codeCells = document.querySelectorAll('div.c-textbook__content > div.highlighter-rouge > div.highlight > pre, div.input_area pre, div.text_cell_render div.highlight pre')
    pageElements['codeCells'] = codeCells;

    codeCells.forEach((codeCell, index) => {
      const id = codeCellId(index)
      codeCell.setAttribute('id', id)
    })
};

initFunction(findCodeCells);

// All cells in general
findInputCells = function() {
    var inputCells = document.querySelectorAll('div.jb_cell')
    pageElements['inputCells'] = inputCells;

    inputCells.forEach((inputCell, index) => {
        const id = inputCellId(index)
        inputCell.setAttribute('id', id)
    })
};

initFunction(findInputCells);
</script>

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->


<!-- Display Thebelab button in each code cell -->
<script>
/**
 * Set up thebelab button for code blocks
 */

const thebelabCellButton = id =>
  `<a id="thebelab-cell-button-${id}" class="btn thebebtn o-tooltip--left" data-tooltip="Interactive Mode">
    <img src="/ml_handbook/assets/images/edit-button.svg" alt="Start interactive mode">
  </a>`


const addThebelabButtonToCodeCells =  () => {

  const codeCells = document.querySelectorAll('div.input_area > div.highlight:not(.output) pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.getElementById("thebelab-cell-button-" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', thebelabCellButton(id));
    }
  })
}

initFunction(addThebelabButtonToCodeCells);
</script>



<script type="text/x-thebe-config">
    {
      requestKernel: true,
      binderOptions: {
        repo: 'jupyter/jupyter-book',
        ref: 'master',
      },
      codeMirrorConfig: {
        theme: "abcdef"
      },
      kernelOptions: {
        name: 'python3',
      }
    }
</script>
<script src="https://unpkg.com/thebelab@0.4.0/lib/index.js" async></script>
<script>
    /**
     * Add attributes to Thebelab blocks
     */

    const initThebelab = () => {
        const addThebelabToCodeCells = () => {
            console.log("Adding thebelab to code cells...");
            // If Thebelab hasn't loaded, wait a bit and try again. This
            // happens because we load ClipboardJS asynchronously.
            if (window.thebelab === undefined) {
                setTimeout(addThebelabToCodeCells, 250)
            return
            }

            // If we already detect a Thebelab cell, don't re-run
            if (document.querySelectorAll('div.thebelab-cell').length > 0) {
                return;
            }

            // Find all code cells, replace with Thebelab interactive code cells
            const codeCells = document.querySelectorAll('.input_area pre')
            codeCells.forEach((codeCell, index) => {
                const id = codeCellId(index)
                codeCell.setAttribute('data-executable', 'true')

                // Figure out the language it uses and add this too
                var parentDiv = codeCell.parentElement.parentElement;
                var arrayLength = parentDiv.classList.length;
                for (var ii = 0; ii < arrayLength; ii++) {
                    var parts = parentDiv.classList[ii].split('language-');
                    if (parts.length === 2) {
                        // If found, assign dataLanguage and break the loop
                        var dataLanguage = parts[1];
                        break;
                    }
                }
                codeCell.setAttribute('data-language', dataLanguage)

                // If the code cell is hidden, show it
                var inputCheckbox = document.querySelector(`input#hidebtn${codeCell.id}`);
                if (inputCheckbox !== null) {
                    setCodeCellVisibility(inputCheckbox, 'visible');
                }
            });

            // Remove the event listener from the page so keyboard press doesn't
            // Change page
            document.removeEventListener('keydown', initPageNav)
            keyboardListener = false;

            // Init thebelab
            thebelab.bootstrap();

            // Remove copy buttons since they won't work anymore
            const copyAndThebeButtons = document.querySelectorAll('.copybtn, .thebebtn')
            copyAndThebeButtons.forEach((button, index) => {
                button.remove();
            });

            // Remove outputs since they'll be stale
            const outputs = document.querySelectorAll('.output *, .output')
            outputs.forEach((output, index) => {
                output.remove();
            });
        }

        // Add event listener for the function to modify code cells
        const thebelabButtons = document.querySelectorAll('[id^=thebelab], [id$=thebelab]')
        thebelabButtons.forEach((thebelabButton,index) => {
            if (thebelabButton === null) {
                setTimeout(initThebelab, 250)
                return
            };
            thebelabButton.addEventListener('click', addThebelabToCodeCells);
        });
    }

    // Initialize Thebelab
    initFunction(initThebelab);
</script>



  <!-- Load the auto-generating TOC -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js" integrity="sha256-haW9DG1S+hUHEJFu5zzGTQNS/QQd5rtOtZQ+5zx7rRQ=" crossorigin="anonymous"></script>
<script>
const initToc = () => {
  if (window.tocbot === undefined) {
    setTimeout(initToc, 250)
    return
  }

  // Check whether we have any sidebar content. If not, then show the sidebar earlier.
  var SIDEBAR_CONTENT_TAGS = ['.tag_full_width', '.tag_popout'];
  var sidebar_content_query = SIDEBAR_CONTENT_TAGS.join(', ')
  if (document.querySelectorAll(sidebar_content_query).length === 0) {
    document.querySelector('nav.onthispage').classList.add('no_sidebar_content')
  }

  // Initialize the TOC bot
  tocbot.init({
    tocSelector: 'nav.onthispage',
    contentSelector: '.c-textbook__content',
    headingSelector: 'h2, h3',
    orderedList: false,
    collapseDepth: 6,
    listClass: 'toc__menu',
    activeListItemClass: "",  // Not using
    activeLinkClass: "", // Not using
  });

}
initFunction(initToc);
</script>


  <!-- Google analytics -->
  <script src="/ml_handbook/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

  <!-- Load custom website scripts -->
  <script src="/ml_handbook/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/ml_handbook/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/ml_handbook/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("http://localhost:4000") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" integrity="sha256-M/Awbb/BYh+Rh0aGjpQid26p1b2OBsrk2k9yAvQxPV0=" crossorigin="anonymous"></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const clipboardButton = id =>
  `<a id="copy-button-${id}" class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/ml_handbook/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  pageElements['codeCells'].forEach((codeCell) => {
    const id = codeCell.getAttribute('id')
    if (document.getElementById("copy-button" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>


  <!-- Hide cell code -->
  <script>
    /**
    Add buttons to hide code cells
    */


    var setCodeCellVisibility = function (inputField, kind) {
        // Update the image and class for hidden
        var id = inputField.getAttribute('data-id');
        var codeCell = document.querySelector(`#${id} div.highlight`);

        if (kind === "visible") {
            codeCell.classList.remove('hidden');
            inputField.checked = true;
        } else {
            codeCell.classList.add('hidden');
            inputField.checked = false;
        }
    }

    var toggleCodeCellVisibility = function (event) {
        // The label is clicked, and now we decide what to do based on the input field's clicked status
        if (event.target.tagName === "LABEL") {
            var inputField = event.target.previousElementSibling;
        } else {
            // It is the span inside the target
            var inputField = event.target.parentElement.previousElementSibling;
        }

        if (inputField.checked === true) {
            setCodeCellVisibility(inputField, "visible");
        } else {
            setCodeCellVisibility(inputField, "hidden");
        }
    }


    // Button constructor
    const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

    var addHideButton = function () {
        // If a hide button is already added, don't add another
        if (document.querySelector('div.tag_hide_input input') !== null) {
            return;
        }

        // Find the input cells and add a hide button
        pageElements['inputCells'].forEach(function (inputCell) {
            if (!inputCell.classList.contains("tag_hide_input")) {
                // Skip the cell if it doesn't have a hidecode class
                return;
            }

            const id = inputCell.getAttribute('id')

            // Insert the button just inside the end of the next div
            inputCell.querySelector('div.input').insertAdjacentHTML('beforeend', hideCodeButton(id))

            // Set up the visibility toggle
            hideLink = document.querySelector(`#${id} div.inner_cell + input + label`);
            hideLink.addEventListener('click', toggleCodeCellVisibility)
        });
    }


    // Initialize the hide buttos
    var initHiddenCells = function () {
        // Add hide buttons to the cells
        addHideButton();

        // Toggle the code cells that should be hidden
        document.querySelectorAll('div.tag_hide_input input').forEach(function (item) {
            setCodeCellVisibility(item, 'hidden');
            item.checked = true;
        })
    }

    initFunction(initHiddenCells);

</script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/ml_handbook/assets/css/styles.css",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://jupyter.org/jupyter-book/intro.html"><img src="/ml_handbook/images/logo/logo.png" class="textbook_logo" id="sidebar-logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">Unboxing Machine Learning</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ml_handbook/intro.html"
        >
          
          Introduction
        </a>

        
      </li>

      
    
      
      
        <li><h2 class="c-sidebar__title">Model Evaluation</li>
        
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry c-sidebar__entry--active"
          href="/ml_handbook/01-RegressionMetrics.html"
        >
          
            1.
          
          Regression
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ml_handbook/02-ClassificationMetrics.html"
        >
          
            2.
          
          Classification
        </a>

        
      </li>

      
    
      
      
        <li><h2 class="c-sidebar__title">Gradient Descent</li>
        
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ml_handbook/03-GradientDescent.html"
        >
          
            3.
          
          Basic Intution (Part I)
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/ml_handbook/04-LinearRegression.html"
        >
          
            4.
          
          Linear Regression (Part II)
        </a>

        
      </li>

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><i class="fa fa-download"></i></button>
    <div class="download-buttons">
        <a href="/ml_handbook/content/01-RegressionMetrics.ipynb" download>
        <button id="interact-button-download" class="interact-button">ORIG</button>
        </a>
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">PDF</button></a>
    </div>
</div>

  <button id="interact-button-thebelab" class="interact-button">Thebelab</button>

  
  






<a href="https://mybinder.org/v2/gh/jupyter/jupyter-book/master?filepath=content%2F01-RegressionMetrics.ipynb"><button class="interact-button" id="interact-button-binder"><img class="interact-button-logo" src="/ml_handbook/assets/images/logo_binder.svg" alt="Interact" />Interact</button></a>
  


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/ml_handbook/search.html" class="topbar-right-button" id="search-button"><i class="fa fa-search"></i></a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Regression-Related-Evaluation-Metrics">Regression Related Evaluation Metrics<a class="anchor-link" href="#Regression-Related-Evaluation-Metrics"> </a></h1><p>Regression problems are the problems where we try to make a prediction on a continuous scale. This chapter aims to help develop (or rediscover) the intuition behind some of these popular metrics, namely $R^2$, for evaluating regression models. Using an open source housing dataset, we first build three different models and thereafter intutitively build various metrics that help evaluate the the performance of the three trained models against each other. We start with basic evaluation metrics such as error, absolute error, etc and eventually try to the build the underlying intutition behind $R^2$.</p>
<h2 id="Predicting-House-Price">Predicting House Price<a class="anchor-link" href="#Predicting-House-Price"> </a></h2><p>Let's assume we are tasked to build a model that can predict house prices. Further, we are provided with an open source Boston city dataset. As shown in the code snippet below, we can load the dataset as a <code>pandas</code> dataframe. In the table below, "price" is the variable we aim to predict and treat the rest of the variables as input features. You can find more information about the individual fields in the dataset over <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names">here</a>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;scipy&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;^internal gelsd&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>


<span class="n">boston</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span>
<span class="n">data</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>354</td>
      <td>0.04301</td>
      <td>80.0</td>
      <td>1.91</td>
      <td>0.0</td>
      <td>0.413</td>
      <td>5.663</td>
      <td>21.9</td>
      <td>10.5857</td>
      <td>4.0</td>
      <td>334.0</td>
      <td>22.0</td>
      <td>382.80</td>
      <td>8.05</td>
      <td>18.2</td>
    </tr>
    <tr>
      <td>294</td>
      <td>0.08199</td>
      <td>0.0</td>
      <td>13.92</td>
      <td>0.0</td>
      <td>0.437</td>
      <td>6.009</td>
      <td>42.3</td>
      <td>5.5027</td>
      <td>4.0</td>
      <td>289.0</td>
      <td>16.0</td>
      <td>396.90</td>
      <td>10.40</td>
      <td>21.7</td>
    </tr>
    <tr>
      <td>192</td>
      <td>0.08664</td>
      <td>45.0</td>
      <td>3.44</td>
      <td>0.0</td>
      <td>0.437</td>
      <td>7.178</td>
      <td>26.3</td>
      <td>6.4798</td>
      <td>5.0</td>
      <td>398.0</td>
      <td>15.2</td>
      <td>390.49</td>
      <td>2.87</td>
      <td>36.4</td>
    </tr>
    <tr>
      <td>255</td>
      <td>0.03548</td>
      <td>80.0</td>
      <td>3.64</td>
      <td>0.0</td>
      <td>0.392</td>
      <td>5.876</td>
      <td>19.1</td>
      <td>9.2203</td>
      <td>1.0</td>
      <td>315.0</td>
      <td>16.4</td>
      <td>395.18</td>
      <td>9.25</td>
      <td>20.9</td>
    </tr>
    <tr>
      <td>110</td>
      <td>0.10793</td>
      <td>0.0</td>
      <td>8.56</td>
      <td>0.0</td>
      <td>0.520</td>
      <td>6.195</td>
      <td>54.4</td>
      <td>2.7778</td>
      <td>5.0</td>
      <td>384.0</td>
      <td>20.9</td>
      <td>393.49</td>
      <td>13.00</td>
      <td>21.7</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We randomly split the data into 80/20 i.e 80% data is used for training and 20% of the data is used for testing. Further, let's assume that we train three different models to predict house prices. The three models we will train are:</p>
<ol>
<li><p><strong>Mean Model:</strong> Assume that the only available information is prices of adjoining houses to your house. Now, if someone asks what's the price of a nearby house, one is likely to guess a value close to the "mean" house price of the adjoining houses. It can be shown that when no information is available other than the target variable, using the expected value (or "mean") of the target variable as the predicted value will minimize the total absolute error. Here, I use the term "mean model" to describe such a model. For every data point, "Mean model" returns a constant value equal to the observed mean value of the target variable in the training dataset. 
As you will see later, this model serves as a great baseline for evaluating other models.</p>
</li>
<li><p><strong>Linear Regression Model:</strong> The second model will use linear regression algorithm. Linear regression and its variants (such as Lasso, ElasticNet, etc) are one of the most popular algorithms to deal with regression problems. For the purpose of this chapter, we will use the ordinary least square algorithm.</p>
</li>
<li><p><strong>Xgboost:</strong> The third model is based on the "Xgboost" algorithm. Xgboost trains multiple decision trees where each tree increases the weight depending on the error observed in the previous tree.</p>
</li>
</ol>
<p>For the purpose of this chapter, it's not important to understand how these different algorithms work. The only motivation for training three different models is to help conceptualize and develop an evaluation metric that allows us to compare different models and determine the best. In the same spirit, we also skip feature engineering and hyper-parameter tunning. These steps are critical to building a good quality model. But the focus of this chapter is not to build the best model for house price prediction but on how to evaluate regression models.</p>
<p>Using training data, below code snippt trains the three models and use the same to predict house price for the houses in our test dataset.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="k">import</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="k">import</span> <span class="n">XGBRegressor</span>

<span class="c1"># Split Data Into Training and Test Dataset </span>
<span class="c1"># so that we use the same training and test dataset </span>
<span class="c1"># to train and test three models. Also setting random state </span>
<span class="c1"># so that we can results are reproducible</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">is_copy</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">test</span><span class="o">.</span><span class="n">is_copy</span> <span class="o">=</span> <span class="kc">None</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Dataset: &quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Dataset: &quot;</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># =====================</span>
<span class="c1"># TRAIN MODELS</span>
<span class="c1"># =====================</span>

<span class="c1"># Mean Model</span>
<span class="c1"># It simply returns mean value based on the training dataset </span>
<span class="c1"># as a prediction. Fixing </span>
<span class="n">mean_model</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">mean_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>

<span class="c1"># Linear Regression</span>
<span class="n">median_model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">median_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>

<span class="c1"># xgboost model</span>
<span class="n">xgboost_model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">()</span>
<span class="n">xgboost_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span>

<span class="c1"># =====================</span>
<span class="c1"># GENERATE PREDICTIONS</span>
<span class="c1"># =====================</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">median_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;xgboost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">xgboost_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">])</span>

<span class="c1">## display results</span>
<span class="n">test</span><span class="p">[[</span><span class="s1">&#39;price&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;regression&#39;</span><span class="p">,</span> <span class="s1">&#39;xgboost&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training Dataset:  (404, 14)
Test Dataset:  (102, 14)
[23:30:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>mean</th>
      <th>regression</th>
      <th>xgboost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>65</td>
      <td>23.5</td>
      <td>21.841832</td>
      <td>30.873149</td>
      <td>26.025826</td>
    </tr>
    <tr>
      <td>107</td>
      <td>20.4</td>
      <td>21.841832</td>
      <td>21.243959</td>
      <td>20.909090</td>
    </tr>
    <tr>
      <td>311</td>
      <td>22.1</td>
      <td>21.841832</td>
      <td>26.982815</td>
      <td>23.956749</td>
    </tr>
    <tr>
      <td>119</td>
      <td>19.3</td>
      <td>21.841832</td>
      <td>20.880395</td>
      <td>21.371815</td>
    </tr>
    <tr>
      <td>486</td>
      <td>19.1</td>
      <td>21.841832</td>
      <td>19.676509</td>
      <td>17.655367</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Error-Distribution-and-Mean-Absolute-Error">Error Distribution and Mean Absolute Error<a class="anchor-link" href="#Error-Distribution-and-Mean-Absolute-Error"> </a></h2><p>The next challenge is determining the best model of the three or to rank order them based on the quality. However, quality is undefined and we need to define it. The first thing that comes to mind is to examine error i.e. difference between actual house price and the predicted value. Note that the error can be positive if the model underpredicts the value of a given house or vice-versa. Since there are hundreds of houses in the test dataset, as shown in the below plot, we can further examine the distribution of error for each model.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># =====================</span>
<span class="c1"># CALCULATE ERROR</span>
<span class="c1"># =====================</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;regression_model_error&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">]</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;xgboost_model_error&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;xgboost&#39;</span><span class="p">]</span>

<span class="c1"># =====================</span>
<span class="c1"># PLOT DISTRIBUTION OF ERRORS</span>
<span class="c1"># FOR THREE MODELS</span>
<span class="c1"># =====================</span>

<span class="c1"># convert wide format to row format so that it</span>
<span class="c1"># easy to visualize and compute statistical properties</span>
<span class="n">errorDF</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">,</span> <span class="s1">&#39;regression_model_error&#39;</span><span class="p">,</span> <span class="s1">&#39;xgboost_model_error&#39;</span><span class="p">])</span> 

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">from</span> <span class="nn">plotnine</span> <span class="k">import</span> <span class="o">*</span>
<span class="n">display</span><span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">errorDF</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="s1">&#39;variable&#39;</span><span class="p">))</span> 
    <span class="o">+</span> <span class="n">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> 
    <span class="o">+</span> <span class="n">theme_xkcd</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">theme</span><span class="p">(</span><span class="n">figure_size</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s2">&quot;Error in house price&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">ggtitle</span><span class="p">(</span><span class="s2">&quot;Distribution of Error&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/01-RegressionMetrics_5_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea ">
<pre>&lt;ggplot: (305548849)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The distribution of error tells a lot about each model. For instance, from the above plot, we can examine that xgboost based model has a much smaller standard deviation as compared to other models. But as an evaluation metric, we desire for a single real number that makes comparing and ranking competing models easier.  Unless there is a significant bias in the model, the error is normally distributed (and as we can observe from the above plot). A normal distribution can be described using two parameters: mean and standard deviation. Thus one option to convert the distribution to a single number that serves as an evaluation criterion is to examine mean error for each model and we can name this evaluation criteria as "mean error". The code snippet below computes the mean and standard deviation for error distribution associated with each model.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># =====================</span>
<span class="c1"># CALCULATE MEAN AND SD</span>
<span class="c1"># =====================</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean and Standard Deviation&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span>
    <span class="n">errorDF</span>
    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;variable&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">]})</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">((</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mean and Standard Deviation
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>variable</th>
      <th colspan="2" halign="left">value</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2</td>
      <td>xgboost_model_error</td>
      <td>0.315741</td>
      <td>3.499984</td>
    </tr>
    <tr>
      <td>1</td>
      <td>regression_model_error</td>
      <td>0.739362</td>
      <td>5.848302</td>
    </tr>
    <tr>
      <td>0</td>
      <td>mean_model_error</td>
      <td>3.427776</td>
      <td>10.276974</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using "mean error" as an evaluation criterion we can conclude that xgboost based model has the smallest error as compared to other models. However, there is an obvious flaw in our conclusion.  Let's assume that we have a model, say Model X, that always over predict i.e. the error is always negative. In this case, the mean error will be negative and let's assume it's -3. Since -3 is less than the mean error of the xgboost based model, we might wrongly conclude that Model X is better than the xgboost based model.</p>
<p>One might jump to fix the problem by taking absolute of mean error as it will again restore xgboost based model as the best quality model. There is, however, another issue. Assume that there are two houses in our test dataset and a model underestimate one by 10K, i.e. error = 10K, and overestimate the other by 10K, i.e error = -10K. Here, the mean error and absolute mean error will be zero. This model should be the best model we can as the absolute mean error can never be less than zero.  However, this doesn't make sense.</p>
<p>The problem with absolute mean error is that the individual errors are not additive. To make the errors additive we can take absolute error and thereafter take the mean of absolute error. Thus in the above example, the mean absolute error will be $ \frac{|-10| + |10|}{2} = 10$. Note that there is a significant difference between "absolute mean error" and our new evaluation metric "mean absolute error". In the former, we first compute mean and then apply absolute function. In the later, we first apply the absolute function to individual errors and thereafter take the mean. For obvious reasons, this new evaluation metric is referred as "Mean Absolute Error" or MAE. Mathematically MAE can be defined as:</p>
$$MAE = \frac{\sum_{i=1}^{N}|\hat{y_i} - y_i|}{N}$$<p>Let's re-evaluate the quality of our three models using MAE.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Conver error into absolute error</span>
<span class="n">errorDF</span><span class="p">[</span><span class="s1">&#39;absolute_error&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">errorDF</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span>
    <span class="n">errorDF</span>
    <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;variable&#39;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;absolute_error&#39;</span><span class="p">:</span> <span class="s1">&#39;mean&#39;</span><span class="p">})</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;absolute_error&#39;</span><span class="p">:</span> <span class="s1">&#39;MAE&#39;</span><span class="p">})</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variable</th>
      <th>MAE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2</td>
      <td>xgboost_model_error</td>
      <td>2.492412</td>
    </tr>
    <tr>
      <td>1</td>
      <td>regression_model_error</td>
      <td>4.061419</td>
    </tr>
    <tr>
      <td>0</td>
      <td>mean_model_error</td>
      <td>7.554703</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The unit of MAE is the same as that of the target variable. This makes MAE easy to understand and interpret. However, "mean" is one of the parameters several parameters related to a distribution and is sensitive to outliers. Hence, sometimes instead of taking the mean of absolute error, "median absolute error" is also reported.</p>
<h2 id="$R^2$">$R^2$<a class="anchor-link" href="#$R^2$"> </a></h2><p>While MAE and its variants are easy to interpret, they have one major shortcoming. These metrics focus on the centrality of the error distribution (i.e. mean or median) and ignore the spread of error. For instance, consider two house prediction models both having MAE of \$10K. However, for one of the model the error ranges from \$5K to \$15K and for another it can range from \$0K to \$50K. In this case,the first model might be more desirable due to its smaller spread. When trying to make a decision about which model is the best, dealing with two separate metrics independently is often challenging and hence one need a single metric that can take into account the whole distribution of errors rather than focusing on the centrality of the errror.</p>
<p>In our search for a better metric, let's revisit some of the core questions we are trying to answer as part of our evaluation strategy. One question that's important is understanding what percentage of houses exhibit less than certain absolute error. We can easily answer this by plotting the cumulative distribution of absolute error as shown below.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># For now ignore this. The below description will help understand this eventually</span>
<span class="n">idealModel</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">errorDF</span><span class="o">.</span><span class="n">absolute_error</span><span class="p">),</span> <span class="mf">1.</span><span class="p">]],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;y1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;y2&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="p">(</span>
    <span class="n">ggplot</span><span class="p">()</span> 
    
    <span class="c1"># we use stat_ecdf function to compuate cumulative distribution and plot the same</span>
    <span class="o">+</span> <span class="n">stat_ecdf</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="s1">&#39;absolute_error&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;variable&#39;</span><span class="p">),</span> <span class="n">data</span><span class="o">=</span><span class="n">errorDF</span><span class="p">,</span> <span class="n">geom</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>
    
    <span class="c1"># plot the idea model</span>
    <span class="o">+</span> <span class="n">geom_segment</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y1&#39;</span><span class="p">,</span> <span class="n">xend</span><span class="o">=</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="n">yend</span><span class="o">=</span><span class="s1">&#39;y2&#39;</span><span class="p">),</span> <span class="n">data</span><span class="o">=</span><span class="n">idealModel</span><span class="p">,</span> <span class="n">linetype</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    
    <span class="c1"># render labels</span>
    <span class="o">+</span> <span class="n">theme_minimal</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s2">&quot;Absolute Error&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s2">&quot;Cumulative Percentage of Houses&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">ggtitle</span><span class="p">(</span><span class="s2">&quot;Cumulative Distribution of Absolute Error For Various Models&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/01-RegressionMetrics_11_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;ggplot: (307586665)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can observe that for the xgboost based model, 95% of the houses have less than 10 unit of absolute error. Whereas only about 75% of houses have less than 10 unit of absolute error for the "mean model".</p>
<p>One thing that also stands out in the above plot is the clear hierarchy of lines. As the model get's better, the closer it's moving towards the top left part of the plot. For instance, the xgboost based model, which is the best of the three based on MAE metric, is closest to the top left part of the plot. Similarly, the "mean model", which is the worst, is farthest from the top left point of the plot. There is a reason for such a behavior. Let's think about an ideal model. An ideal model will zero absolute error for 100% of the test cases. Shown by the black dotted line in the above plot, the cumulative distribution plot for this ideal model will overlap with y-axis and extend up to 1.  Thus, as our models will get better the closer they should move towards the cumulative distribution of the ideal model.</p>
<p>We can further quantify the notion of "closeness" to the ideal model as the area between the ideal model and the cumulative distribution plot of a given model. Let's represent this area by $AAC$ or "area above curve$. <strong>AAC reflects how far is a given model from the ideal model or the possible improvement opportunity</strong>, For instance, in the below plot the red region indicates the AAC for the xgboost based model. Similarly, AAC of the "mean model" will be equal to green region plus red region. Mathematically, we can define AAC as:</p>
$$ AAC(m) = \int_0^{1}{|y-\hat{y}_m|} ~ \approx ~ \sum_i{|y_i-\hat{y}_{m, i}|} $$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">,</span> <span class="s1">&#39;xgboost_model_error&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">abs</span><span class="p">(),</span> <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">,</span> <span class="s1">&#39;xgboost_model_error&#39;</span><span class="p">])</span>
<span class="n">meanCount</span><span class="p">,</span> <span class="n">binEdges1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">value</span><span class="p">)])</span>
<span class="n">meanCumSum</span> <span class="o">=</span> <span class="n">meanCount</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">xgboostCount</span><span class="p">,</span> <span class="n">binEdges2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;xgboost_model_error&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">value</span><span class="p">)])</span>
<span class="n">xgboostCumSum</span> <span class="o">=</span> <span class="n">xgboostCount</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">binEdges1</span><span class="p">,</span> <span class="n">binEdges2</span><span class="p">),</span> <span class="s2">&quot;Bins are different&quot;</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;absolute_error&#39;</span><span class="p">:</span> <span class="n">binEdges1</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">binEdges1</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="s1">&#39;mean_cumsum&#39;</span><span class="p">:</span> <span class="n">meanCumSum</span><span class="p">,</span>
    <span class="s1">&#39;xgboost_cumsum&#39;</span><span class="p">:</span> <span class="n">xgboostCumSum</span>
<span class="p">})</span>

<span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;absolute_error&#39;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">geom_ribbon</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="o">=</span><span class="s1">&#39;mean_cumsum&#39;</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="s1">&#39;xgboost_cumsum&#39;</span><span class="p">),</span> <span class="n">fill</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">geom_ribbon</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="o">=</span><span class="s1">&#39;xgboost_cumsum&#39;</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">fill</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">geom_ribbon</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="s1">&#39;mean_cumsum&#39;</span><span class="p">),</span> <span class="n">fill</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">xlab</span><span class="p">(</span><span class="s2">&quot;Absolute Error&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">ylab</span><span class="p">(</span><span class="s2">&quot;Cumulative Percentage of Houses&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">ggtitle</span><span class="p">(</span><span class="s2">&quot;Cumulative distribution of xgboost based model and mean model&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/01-RegressionMetrics_13_0.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;ggplot: (307557901)&gt;</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The advantage of AAC over MAE is that it takes into account the complete distribution of the absolute error and further quantify how far is a given model from the ideal model. However, as an evaluation metric, it's missing many desirable characteristics. Some of the key concerns are:</p>
<ol>
<li><p>AAC is inversely related to model quality. As AAC increases, model quality deteriorates and vice-versa and thereby is counter-intuitive.</p>
</li>
<li><p>AAC is bounded only on one side.  IOA can range from 0 to infinity. As the model quality deteriorates and AAC increases to infinite. A good metric should be bounded between 0 and 1 or -1 to 1 to make it easy to interpret.</p>
</li>
<li><p>AAC is not differentiable. AAC uses "absolute" function, which is non-differentiable. For optimization, it is often desirable to have a function that is differentiable.</p>
</li>
</ol>
<p>Let's focus on the first problem. One simple fix to address the inverse relationship problem is to consider the area under the curve (AUC). In the above plot, AUC for the XGboost based model is the sum of the green and the grey regions. Conceptually, AUC represents improvement made by a given model as compared to the worst model. Theoretically, the worst model has an infinite absolute error for 100% test cases. Thus, the cumulative distribution plot of it overlaps with the x-axis and extends to infinity. Using the worst model, however, complicates computing AUC and hence we need some other baseline model. The "mean model," one of the three models that we trained, is another good baseline. It uses no additional features other than the target variable itself and, in practice, is the worst model that the machine can learn. Let's redefine AUC as $AUC_{mean}$ to represent the area the cumulative distribution plot of a given model and the mean model. In the above plot, the green region represents $AUC_{mean}$ for the XGboost based model. Mathematically, we can represent $AUC_{mean}$ as</p>
$$ AUC_{mean}(m) =  \int_0^{1}{|\hat{y}_m-\bar{y}|} ~ \approx ~ \sum_i{|\hat{y}_m-\bar{y}|} $$<p>where</p>
<ul>
<li>m represents a given model, such as XGboost based model</li>
<li>$\hat{y}_m$ represents predicted target value for a given test case</li>
<li>$\bar{y}$ represents mean predicted target value.</li>
</ul>
<p>We can also rewrite $AUC_{mean}$ in terms of AAC as shown below</p>
$$ AUC_{mean}(m) = AAC(mean) - AAC(m) $$<p>where</p>
<ul>
<li>$AAC(mean)$ represents AAC for the mean model. </li>
<li>$AAC(m)$ represents AAC for a given model. </li>
</ul>
<p>$AUC_{mean}$ can range from $-\infty$ to $\infty$. It will be negative when our model is worse than the mean model and hence the cumulative plot of the given model is below the mean model. However, as discussed earlier, a bounded metric is much more easy to interpret and hence desirable. One way to bound $AUC_{mean}$ above is to normalize it by AAC(mean). That we redefine $AUC_{mean}$ as</p>
$$ AUC_{mean}(m) = \frac{AAC(mean) - AAC(m)}{AAC(mean)} $$<p>or</p>
$$ AUC_{mean}(m) = 1 - \frac{AC(m)}{AAC(mean)} $$<p>Theoretically, based on the new definition, AUC<em>{mean} can range from $-\infty$ to 1. It is 1 when area above the curve for the given model, i.e. $AAC(m)$ is equal to 0. In that case we have an ideal model that is accurate for 100% of the test cases. $AUC</em>{mean}(m)$ will be zero when the model is same as the mean model. However if its worse than the mean model then it can range from anywhere 0 to $-\infty$. In pratcise, however, $AUC_{mean}(m)$ can only range from 0 to 1. If it is less than 0, then one can essentially replace the learned model with the mean model.</p>
<p>One last issue with AAC is that its not deferentiable due to usage of the "absolute" function. We used the "absolute" function to make the errors additive. To fix this, we can replace the "absolute" function with the "square" function. Thus we can rewrite AUC definition as</p>
$$ AUC_{mean}(m) = 1 - \frac{AC(m)}{AAC(mean)} \approx 1 - \frac{\sum{(y-\hat{y})^2}}{\sum{(y-\bar{y})^2}}$$<p>The above equation should start looking familiar. Not only we rediscovered intuition behind $R^2$ but can also visualize the metric. The below code snippet computes $R^2$ based on the idea explained above and also using sklearn library.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Manually calculating R2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Manually Computing R2&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Xgboost Model: &quot;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;xgboost&#39;</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Regression Model: &quot;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;regression_model_error&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Model: &quot;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean_model_error&#39;</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>


<span class="c1"># Using sklearn</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Using Sklearn&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">r2_score</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Decision Tree: &quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;xgboost&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Regression Model: &quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;regression&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Model: &quot;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Manually Computing R2
Xgboost Model:  0.8948728277178886
Regression Model:  0.7041704429324553
Mean Model:  0.0

Using Sklearn
Decision Tree:  0.8830617869680325
Regression Model:  0.6709339839115636
Mean Model:  -0.11235002800380478
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note: For the mean model one might expect $R^2 = 0$. However using sklear we get non zero value. That's because sklearn is computing mean house price based on the test dataset.</p>
<p>Apart from "Mean Absolute Error" and $R^2$, there are few other metrics, such as squared error, squared log error, etc., that are popularly used when evaluating a regression model. A good starting to find more about these metrics is the list of implemented metrics in <code>sklear</code> library over <a href="http://scikit-learn.org/stable/modules/model_evaluation.html">here</a>.</p>
<p>One might also find it useful to read about adjusted $R^2$ metric. $R^2$ doesn't penalize for the number of features and is addressed by adjusted $R^2$ metric. Hopefully this chapter will now make it easy to understand some of these variants of $R^2$ and other regression metrics.</p>

</div>
</div>
</div>
</div>

 


            </div>
            <nav class="c-page__nav">
  
    
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/ml_handbook/intro.html">
       <span class="u-margin-right-tiny"></span> Introduction
    </a>
  

  
    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/ml_handbook/02-ClassificationMetrics.html">
      Classification <span class="u-margin-right-tiny"></span> 
    </a>
  
</nav>

            <footer>
  <p class="footer">This page was created by <a href="https://github.com/jupyter/jupyter-book/graphs/contributors">The Jupyter Book Community</a></p>
</footer>

        </div>
      </main>
    </div>
  </body>
</html>
