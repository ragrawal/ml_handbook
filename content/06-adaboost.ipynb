{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:09.100692Z",
     "start_time": "2019-12-06T01:52:07.920555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:09.983193Z",
     "start_time": "2019-12-06T01:52:09.947559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>12.34</td>\n",
       "      <td>22.22</td>\n",
       "      <td>79.85</td>\n",
       "      <td>464.5</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.05370</td>\n",
       "      <td>0.02822</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.06761</td>\n",
       "      <td>...</td>\n",
       "      <td>28.68</td>\n",
       "      <td>87.36</td>\n",
       "      <td>553.0</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.2338</td>\n",
       "      <td>0.16880</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.09082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.05888</td>\n",
       "      <td>...</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>12.99</td>\n",
       "      <td>14.23</td>\n",
       "      <td>84.08</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.03738</td>\n",
       "      <td>0.02098</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.07238</td>\n",
       "      <td>...</td>\n",
       "      <td>16.91</td>\n",
       "      <td>87.38</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.14500</td>\n",
       "      <td>0.05850</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>0.10090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "163        12.34         22.22           79.85      464.5          0.10120   \n",
       "439        14.02         15.66           89.59      606.5          0.07966   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "494        13.16         20.54           84.06      538.7          0.07335   \n",
       "336        12.99         14.23           84.08      514.3          0.09462   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "163           0.10150         0.05370              0.02822         0.1551   \n",
       "439           0.05581         0.02087              0.02652         0.1589   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "494           0.05275         0.01800              0.01256         0.1713   \n",
       "336           0.09965         0.03738              0.02098         0.1652   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "163                 0.06761  ...          28.68            87.36       553.0   \n",
       "439                 0.05586  ...          19.31            96.53       688.9   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "494                 0.05888  ...          28.46            95.29       648.3   \n",
       "336                 0.07238  ...          16.91            87.38       576.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "163            0.1452             0.2338          0.16880   \n",
       "439            0.1034             0.1017          0.06260   \n",
       "3              0.2098             0.8663          0.68690   \n",
       "494            0.1118             0.1646          0.07698   \n",
       "336            0.1142             0.1975          0.14500   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "163               0.08194          0.2268                  0.09082       1  \n",
       "439               0.08216          0.2136                  0.06710       1  \n",
       "3                 0.25750          0.6638                  0.17300       0  \n",
       "494               0.04195          0.2687                  0.07429       1  \n",
       "336               0.05850          0.2432                  0.10090       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load breast cancer dataset\n",
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "# convert to pandas data frame\n",
    "features = data.feature_names\n",
    "dataDF = pd.DataFrame(data.data, columns=features)\n",
    "\n",
    "# add binary target variable\n",
    "target = 'target'\n",
    "dataDF['target'] = data.target\n",
    "\n",
    "# display \n",
    "dataDF.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:41.764827Z",
     "start_time": "2019-12-06T01:52:41.757107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (455, 31)\n",
      "Validation:  (57, 31)\n",
      "Test:  (57, 31)\n"
     ]
    }
   ],
   "source": [
    "# split data into train, validation and test\n",
    "n = dataDF.shape[0]\n",
    "sizes = [int(0.8 * n), int(0.9 * n)]\n",
    "trainDF, validationDF, testDF = np.split(dataDF.sample(frac=1, random_state=10), sizes)\n",
    "\n",
    "print(\"Train: \", trainDF.shape)\n",
    "print(\"Validation: \", validationDF.shape)\n",
    "print(\"Test: \", testDF.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T16:39:45.584828Z",
     "start_time": "2019-12-03T16:39:45.580917Z"
    }
   },
   "source": [
    "# Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:43.215284Z",
     "start_time": "2019-12-06T01:52:43.213099Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:44.978111Z",
     "start_time": "2019-12-06T01:52:44.621797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "model.fit(trainDF[features], trainDF[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:45.628571Z",
     "start_time": "2019-12-06T01:52:45.624068Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(testDF[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:52:46.684833Z",
     "start_time": "2019-12-06T01:52:46.681240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(testDF[target], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T16:35:35.280805Z",
     "start_time": "2019-12-03T16:35:35.277073Z"
    }
   },
   "source": [
    "# Using Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of adaboost, acronym for \"Adaptive Boosting\", is simple. Imagine back your school days preparing for a exam. Once you have scanned through and praticsed the whole syllabalus, you would spend more time praticising hard problems. Boosting is based on the same principle. Once we have our initial classifier that treats each data point equally, we start focusing more on data points for which our previous classifier was wrong. The idea here is that the direction of gradient descent is more influenced by data points for which our model having trouble dealing with. One simple way to achieve this is by increasing the weight of the sample. Recall, hwo in chapter [4](04-linearregression.html), we used mean square error (MSE) as our objective function to minimize and it is computed as follows:\n",
    "\n",
    "$$MSE = \\frac{1}{m} \\sum_{i=1}^{m}\\left[y - \\sum_{i=1}^{n}\\theta_iX_i\\right]^2$$\n",
    "\n",
    "We can generalize, the above function to incorporate sample weight, say $w_i$, as:\n",
    "\n",
    "$$MSE = \\frac{1}{m} \\sum_{i=1}^{m}\\left[w_i\\left(y - \\sum_{i=1}^{n}\\theta_iX_i\\right)\\right]^2$$\n",
    "\n",
    "Now, if we take partial derivative of the above equation, we get direction of gradient descent that is influenced by the weight of the sample. Thus, we can assign higher weight to difficult data points and influence the direction of the gradient descent towards these difficult data points.\n",
    "\n",
    "The idea make sense but the problem remains is how to find optimal weight for difficult data points. If it's too low then the gradient descent direction might not change at all and if it's too hight then the gradient descent might gets too much influenced by hard data points and start having trouble with other data points that our model previously able to deal with. Adaboost solves this problem. \n",
    "\n",
    "There is still one challenge, \n",
    "\n",
    "\n",
    "* AdaBoost --> adaptive boosting\n",
    "\n",
    "**References**:\n",
    "1. [Boosting with Adaboost and Gradient Boosting](https://medium.com/diogo-menezes-borges/boosting-with-adaboost-and-gradient-boosting-9cbab2a1af81)\n",
    "2. [A comprehensive guide to ensemble learning](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T01:58:02.526128Z",
     "start_time": "2019-12-06T01:58:02.030084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626373626373627\n"
     ]
    }
   ],
   "source": [
    "sample_weights = np.repeat(1./trainDF.shape[0], trainDF.shape[0])\n",
    "model1 = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "model1.fit(trainDF[features], trainDF[target])\n",
    "predicted = model1.predict(trainDF[features])\n",
    "print(accuracy_score(trainDF[target], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T02:51:11.043896Z",
     "start_time": "2019-12-04T02:51:11.028260Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
